---
title: "Join Enviro Variables for Tampa Bay"
output: html_document
---

```{r setup, include=FALSE}
require ("knitr")
knitr::opts_chunk$set(echo = TRUE)
opts_knit$set(root.dir ="U:/PhD_projectfiles/Raw_Data/Seatrout_FIM_Data/FIMData/NEWNov7" )
```

## About

This is an R Markdown document. 
This document details how environmental data not available within the FIM dataset are appended to the FIM catch data set. 

## Set File Locations ###

Can't Use setwd for knitr so one is chosen as the root directory in the set up chunk and then if I have to reference other places then I will use other locations defined below. 
  
```{r}
personal_comp = "~/Desktop/PhD project/Projects/Seatrout/Data/Raw Survey Data/Seatrout FIM Data"
work_comp= "U:/PhD_projectfiles/Raw_Data/Seatrout_FIM_Data/FIMData/NEWNov7"
phys_dat = "U:/PhD_projectfiles/Raw_Data/Seatrout_FIM_Data/Raw Data from fimaster-data-sas-inshore"
enviro_dat = "U:/PhD_projectfiles/Raw_Data/Environmental_Data"

```

## Load Packages 
* haven-to load sas7bdat data
* dplyr- to do df manipulation
* geosphere-  closest lat/long neighbors
* cluster- to determine medoids

```{r}
library(haven) 
library(dplyr) 
library(geosphere)
library(cluster)
```

## Import Data Sets/ About Data 
The fisheries independent monitoring data (FIM) contain positive and zero catch observations of Spotted seatrout for every single haul conducted in each estuary since sampling inception.  

Load FIM Data and select the important recruitment months for each zone so that we are only selecting young-of-the-year individuals. Also, there was a typo in variable name so adjust it to be consistent with other dataframes. 
```{r Load AP}
ap = subset(read_sas("ap_yoy_cn_c.sas7bdat"), month %in% c(6,7,8,9,10,11)) %>% mutate(bUnk=bunk) %>% select(-bunk) 
```
 Load the hydro dataset that contains Depth where the observation was taken, Temperature, Conductivity, pH, Salinity, Dissolved O2
```{r Load AP 2}
ap_hyd <- subset(read_sas("ap_yoy_cn_hyd.sas7bdat")) 
```
Load the physical data set that contains secchi depth, a proxy for turbidity and turn Reference into a character. Reference will be used as a matching variable. 

```{r Load AP 3}
ap_phys <- read_sas(paste(phys_dat, "apm_physical.sas7bdat", sep="/")) %>% select(Reference, Secchi_on_bottom, Secchi_depth)
ap_phys$Reference <- as.character(ap_phys$Reference)
```

Load the hydro dataset that contains Depth where the hydro observation was taken, Temperature, Conductivity, pH, Salinity, Dissolved O2.it appears at some stations more than 1 hydro observation was recorded so there are duplicate station records. Just select the unique ones.At this point, I have no idea to know which hydro observation is more "accurat" for a certain station. 

``` {r Load AP 4}
ap_hyd <- subset(read_sas("ap_yoy_cn_hyd.sas7bdat")) 
ap_hyd <- ap_hyd[!duplicated(ap_hyd$Reference),]
```
Match merge the catch dataframe (ap) with the physical data frame (ap_phys) using the variable Reference. Then again left_join in the hydro (ap_hyd) dataset by reference. Then reorder the columns alphabetically. 

```{r Load AP 5}
ap <- left_join(ap, ap_phys, by="Reference") %>% left_join(ap_hyd, by="Reference")
ap <- ap %>% select(noquote(order(colnames(ap))))  #reorders the columns alphabetically 
```

Do this for all other estuaries.

# TB
```{r LoadTB}
tb = subset(read_sas("tb_yoy_cn_c.sas7bdat"), month %in% c(4,5,6,7,8,9,10)) 
#tb_phys <- read_sas("~/Desktop/PhD project/Projects/Seatrout/Data/Raw Survey Data/Seatrout FIM Data/tbm_physical.sas7bdat") %>% select(Reference, Secchi_on_bottom, Secchi_depth)
tb_phys <- read_sas(paste(phys_dat, "tbm_physical.sas7bdat", sep="/")) %>% select(Reference, Secchi_on_bottom, Secchi_depth)
tb_phys$Reference <- as.character(tb_phys$Reference)
tb_hyd <- subset(read_sas("tb_yoy_cn_hyd.sas7bdat")) 
tb_hyd <- tb_hyd[!duplicated(tb_hyd$Reference),]
tb <- left_join(tb, tb_phys, by="Reference") %>% left_join(tb_hyd, by="Reference")
tb <- tb %>% select(noquote(order(colnames(tb))))  #reorders the columns alphabetically 
```

Clean TB. Add in missing lat and long based on the Zone. I.e. if lat and long is missing then use lat and long for similar zone. This is necessary to be able to match any environmental data based on time and space. 

```{r clean TB}
unique(tb$Zone)
unique(subset(tb, is.na(Longitude))$Zone) #assume if its missing Long then its also missing Lat
```
Determine Zone-based medoids to apply to reference values (aka hauls) that have missing Lat Longs

```{r TB Zone specific Medoids}

tb_medA <- matrix(pam(subset(tb, Zone=="A" & !is.na(Longitude) & !is.na(Latitude), select=c("Longitude", "Latitude")),1)$medoids)
sum(is.na(tb_medA))

tb_medC <- matrix(pam(subset(tb, Zone=="C" & !is.na(Longitude) & !is.na(Latitude), select=c("Longitude", "Latitude")),1)$medoids)
sum(is.na(tb_medC))

tb_medD <- matrix(pam(subset(tb, Zone=="D" & !is.na(Longitude) & !is.na(Latitude), select=c("Longitude", "Latitude")),1)$medoids)
sum(is.na(tb_medD))

tb_medE <- matrix(pam(subset(tb, Zone=="E" & !is.na(Longitude) & !is.na(Latitude), select=c("Longitude", "Latitude")),1)$medoids)
sum(is.na(tb_medE))

tb_medM <- matrix(pam(subset(tb, Zone=="M" & !is.na(Longitude) & !is.na(Latitude), select=c("Longitude", "Latitude")),1)$medoids)
sum(is.na(tb_medM))
```
Apply zone-specific medoids to missing Long and Lat. Do this with new varaibles NewLong and NewLat 
```{r TB apply medoids to missing lat/long}
TB_main <- tb %>% mutate(NewLong = ifelse(Zone == "A" & is.na(Longitude), tb_medA[1,],  ifelse(Zone=="C" & is.na(Longitude), tb_medC[1,], ifelse(Zone == "D" & is.na(Longitude), tb_medD[1,], ifelse(Zone=="E" & is.na(Longitude), tb_medE[1,], ifelse(Zone == "M" & is.na(Longitude), tb_medM[1,], tb$Longitude))))), NewLat = ifelse(Zone == "A" & is.na(Latitude), tb_medA[2,],  ifelse(Zone=="C" & is.na(Latitude), tb_medC[2,], ifelse(Zone == "D" & is.na(Latitude), tb_medD[2,], ifelse(Zone=="E" & is.na(Latitude), tb_medE[2,], ifelse(Zone == "M" & is.na(Latitude), tb_medM[2,], tb$Latitude))))))

TB_main$year <- as.numeric(TB_main$year)
TB_main$month <- as.numeric(TB_main$month)

sum(is.na(TB_main$NewLong))                         
sum(is.na(TB_main$NewLat))   
```

Load all accessory environmental variables for Tampa Bay
* Nitrogen
* Phosphorous
* Max Air Temp-CD3
* Min Air Temp-CD3
* Palmer Z-CD3
* Rainfall
* Long-term Salinity
* Seagrass Acreage
* Streamflow
* Water Temperature 
```{r Load TB Enviro Data}
tb_nit1 <- read.csv(paste(enviro_dat, "Nutrients/Nitrogen/Nitrogen_Hillsborough_Bay_EPC_Routine.csv", sep="/"))
tb_nit2 <- read.csv(paste(enviro_dat, "Nutrients/Nitrogen/Nitrogen_Middle_Lower_Tampa_Bay_EPC_Routine.csv", sep="/"))
tb_nit3 <- read.csv(paste(enviro_dat, "Nutrients/Nitrogen/Nitrogen_Old_Tampa_Bay_EPC_Routine.csv", sep="/"))

tb_p1 <- read.csv(paste(enviro_dat, "Phosphorous/Phosphorous_Hillsborough_Bay_EPC_Routine.csv", sep="/"))
tb_p2 <- read.csv(paste(enviro_dat, "Phosphorous/Phosphorous_Lower_Tampa_Bay_EPC_Routine.csv", sep="/"))
tb_p3 <- read.csv(paste(enviro_dat, "Phosphorous/Phosphorous_Middle_Tampa_Bay_EPC_Routine.csv", sep="/"))
tb_p4 <- read.csv(paste(enviro_dat, "Phosphorous/Phosphorous_Old_Tampa_Bay_EPC_Routine.csv", sep="/"))

tb_nit <- rbind(tb_nit1, tb_nit2, tb_nit3)
tb_ph = rbind(tb_p1, tb_p2, tb_p3, tb_p4)
tb_maxT = read.csv(paste(enviro_dat,"AirTemp/Max_Temp_CD3.csv", sep="/")) 
tb_minT = read.csv(paste(enviro_dat,"AirTemp/Min_Temp_CD3.csv", sep="/")) 

tb_PalZ = read.csv(paste(enviro_dat,"PalmerZ/PalmerZ_CD3.csv", sep="/")) 

tb_r1 = read.csv(paste(enviro_dat,"Rainfall/TB_Rainfall_89_97.csv", sep="/"))
tb_r2 = read.csv(paste(enviro_dat,"Rainfall/TB_Rainfall_98_07.csv", sep="/")) 
tb_r3 = read.csv(paste(enviro_dat,"Rainfall/TB_Rainfall_89_97.csv", sep="/")) 
```














Need to match the nitrogen observation spatially and temporally with the catch observations (to create observations at month of haul- monthly present observations) AS WELL as creating an average nitrogen load prior to 'recruitment' timeframe (to create time lagged). 

Get Year and Month in the right format to match to the TB_main dataframe. 
```{r Format Nitrogen -strip time}
tb_nit$SampleDate <- as.factor(tb_nit$SampleDate)
tb_nit <- tb_nit %>% mutate(Date = as.Date(SampleDate, format = " %m/%d/%Y"))
tb_nit$Date <- as.character(tb_nit$Date)

tb_nit <- tb_nit %>% mutate(Year = substr(Date, 1,4), Month = substr(Date, 6,7)) %>% subset(Characteristic %in% c("Nitrogen") & (Year >1988 & Year<2016)) %>% select(Actual_Latitude, Actual_Longitude, Characteristic,Parameter,Result_Unit, Result_Value, Year, Month, StationID)
tb_nit$Year <- as.numeric(tb_nit$Year)
tb_nit$Month <- as.numeric(tb_nit$Month)
```

Match the nitrogen observation with catch observation based on year, month, and closest Lat and Long.Must have same year, same month, and closest Lat observation then append on nitrogen observation. Going to match lat and long by fuzzy matching and month and year exactly. 

Starting with lat and long fuzzy matching because it's trickier and requires some determination of the fuzzy match. 

```{r}
range(unique(tb_nit$Actual_Latitude)) #determine the total range of latitudes in the TB_nit
#27.5737 - 27.9904
range(unique(TB_main$NewLat)) #determine the total range of lat in the TB_main
# 27.466 -  28.03467

range(unique(tb_nit$Actual_Longitude)) #determine the total range of longs in the TB_nit
# -82.7441 - -82.4093
range(unique(TB_main$NewLong))
# -82.831 - -82.333
```
Determine difference between minimum lats of tb_nit and TB_main and difference between maximum lats of tb_nit and TB_main to determine how far or fuzzy things could be.
Do this same thing for longitude. 
```{r}
min(unique(tb_nit$Actual_Latitude)) - min(unique(TB_main$NewLat)) #0.1068669
max(unique(tb_nit$Actual_Latitude)) - max(unique(TB_main$NewLat)) #0.0442667

min(unique(tb_nit$Actual_Longitude)) - min(unique(TB_main$NewLong)) #0.0868976
max(unique(tb_nit$Actual_Longitude)) - max(unique(TB_main$NewLong)) #0.07563469
```
Fuzzy lat distance must be at least 0.1068669 or else the minimum lat observations from the TB_main will not be able to find a fuzzy match. In other words, a fuzzy match of less than that, say for the distance between maximum (0.044), will mean that the minimum lats will not find a match because they are separated by 0.1068669

Fuzzy long distance must be at least 0.0868976 per above logic. 

Run the loop using the defined fuzzy match.

```{r}
fuzzy_lat = max(min(unique(tb_nit$Actual_Latitude)) - min(unique(TB_main$NewLat)), max(unique(tb_nit$Actual_Latitude)) - max(unique(TB_main$NewLat)))

fuzzy_long = max(min(unique(tb_nit$Actual_Longitude)) - min(unique(TB_main$NewLong)),max(unique(tb_nit$Actual_Longitude)) - max(unique(TB_main$NewLong)))


TB_main =TB_main[1:5,]

selected <- NULL

for(i in 1:nrow(TB_main))
{
  # re-initialize these data structs for new pass
  match_matrix <- NULL
  #names(match_matrix) <- c("catch month", "catch year", "refID", "nit_val", "nit_lat","nit_long","dist")
  TBcomb <- data.frame(Month=numeric(),Year=numeric(),RefID=numeric(),Nitrogen=numeric(),Latitude=numeric(),Longitude=numeric())
  hit_counter = 1
  
  #define some variables
  catch_year=TB_main[i,59]
  catch_month=TB_main[i,30]
  catch_lat=TB_main[i,63]
  catch_long=TB_main[i, 62]
  catch_ref = TB_main[i,41]
  TB_cor = as.numeric(c(TB_main[i,62], TB_main[i,63]))
  
  for(j in 1:nrow(tb_nit))
  {
    #define some variables
    nit_year=tb_nit[j,7]
    nit_month=tb_nit[j,8]
    nit_lat =tb_nit[j,1]
    nit_long = tb_nit[j,2]
    nit_val = tb_nit[j,6]
    
    if (is.na(catch_year) | is.na(catch_month) | is.na(catch_lat) | is.na(catch_long))
    {
      print("NA Found")
    }
    else if((catch_year==nit_year)&(catch_month==nit_month))
    {
      #defining box to place around each coordinate pair assocaited with catch
      # this reduces the amount of coordinate points that are selected from within tb_nit that are then used in a pairwise distance comparison
      
      fuzzymax_lat = catch_lat +fuzzy_lat #TB_main_sub$NewLat
      fuzzymin_lat = catch_lat -fuzzy_lat
      fuzzymax_long = catch_long + fuzzy_long #TBmain$NewLong
      fuzzymin_long = catch_long - fuzzy_long
      
      if((nit_lat > fuzzymin_lat) & (nit_lat < fuzzymax_lat) & (nit_long > fuzzymin_long) & (nit_long < fuzzymax_long)) 
        #if the lat long of nitrogen falls within the fuzzy lat long boundaries of the catch lat long found above then it will add into the dataframe below 
      {
        
        # TBcomb[hit_counter,1] = catch_month
        # TBcomb[hit_counter,2] = catch_year
        # TBcomb[hit_counter,3] = catch_ref
        # TBcomb[hit_counter,4] = nit_val #result value
        # TBcomb[hit_counter, 5] = nit_lat
        # TBcomb[hit_counter, 6] = nit_long
        # hit_counter = hit_counter + 1
        
        m=NULL
        m[1] = catch_month
        m[2]=catch_year
        m[3]= catch_ref     
        m[4] = nit_val
        m[5] = nit_long
        m[6] = nit_lat
        m[7]= as.numeric(NA) # placeholder for distance 
        
        match_matrix <- rbind(match_matrix,m)
        mm_mat <- matrix(unlist(match_matrix),nrow=nrow(match_matrix))
        mm_mat[,7] = distm(mm_mat[,5:6], TB_cor)
        mm_df <- data.frame(mm_mat)
        colnames(mm_df) <- c("a", "b", "c", "d", "e", "f", "g")
        mm_df$g <- as.numeric(as.character(mm_df$g))
        
        nit_station_match = NULL
        nit_station_match <- as.matrix(mm_df[mm_df$g == min(mm_df$g),])
        #selected <- rbind(selected, nit_station)
        
      }
    }
  }
  selected <- rbind(selected, nit_station_match)
}

```



      

#CK
```{r Load CK, include =FALSE}
ck = subset(read_sas("ck_yoy_cn_c.sas7bdat"),  month %in% c(5,6,7,8,9,10,11))
#ck_phys <- read_sas("~/Desktop/PhD project/Projects/Seatrout/Data/Raw Survey Data/Seatrout FIM Data/ckm_physical.sas7bdat") %>% select(Reference, Secchi_on_bottom, Secchi_depth)
ck_phys <- read_sas(paste(phys_dat, "ckm_physical.sas7bdat", sep="/")) %>% select(Reference, Secchi_on_bottom, Secchi_depth)
ck_phys$Reference <- as.character(ck_phys$Reference)
ck_hyd <- subset(read_sas("ck_yoy_cn_hyd.sas7bdat")) 
ck_hyd <- ck_hyd[!duplicated(ck_hyd$Reference),]
ck <- left_join(ck, ck_phys, by="Reference") %>% left_join(ck_hyd, by="Reference")
ck <- ck %>% select(noquote(order(colnames(ck))))  #reorders the columns alphabetically 
```
             
                         
#CH
``` {r Load CH, include=FALSE}
ch = subset(read_sas("ch_yoy_cn_c.sas7bdat"), month %in% c(4,5,6,7,8,9,10)) %>% mutate(bUnk=bunk) %>% select(-bunk) 
#ch_phys <- read_sas("~/Desktop/PhD project/Projects/Seatrout/Data/Raw Survey Data/Seatrout FIM Data/chm_physical.sas7bdat") %>% select(Reference, Secchi_on_bottom, Secchi_depth)
ch_phys <- read_sas(paste(phys_dat, "chm_physical.sas7bdat", sep="/")) %>% select(Reference, Secchi_on_bottom, Secchi_depth)
ch_phys$Reference <- as.character(ch_phys$Reference)
ch_hyd <- subset(read_sas("ch_yoy_cn_hyd.sas7bdat")) 
#Also duplicated References in ch_hyd
ch_hyd <- ch_hyd[!duplicated(ch_hyd$Reference),]
ch <- left_join(ch, ch_phys, by="Reference") %>% left_join(ch_hyd, by="Reference")
ch <- ch %>% select(noquote(order(colnames(ch))))  #reorders the columns alphabetically 
```

#IR
```{r Load IR, include=FALSE}
ir = subset(read_sas("ir_yoy_cn_c.sas7bdat"), month %in% c(5,6,7,8,9,10,11)) 
#ir_phys <- read_sas("~/Desktop/PhD project/Projects/Seatrout/Data/Raw Survey Data/Seatrout FIM Data/irm_physical.sas7bdat") %>% select(Reference, Secchi_on_bottom, Secchi_depth)
ir_phys <- read_sas(paste(phys_dat, "irm_physical.sas7bdat", sep="/")) %>% select(Reference, Secchi_on_bottom, Secchi_depth)
ir_phys$Reference <- as.character(ir_phys$Reference)
ir_hyd <- subset(read_sas("ir_yoy_cn_hyd.sas7bdat")) 
#Also duplicated References in ir_hyd
ir_hyd <- ir_hyd[!duplicated(ir_hyd$Reference),]
ir <- left_join(ir, ir_phys, by="Reference") %>% left_join(ir_hyd, by="Reference")
ir <- ir %>% select(noquote(order(colnames(ir))))  #reorders the columns alphabetically 
```

#JX
```{r Load JX, include=FALSE}
jx = subset(read_sas("jx_yoy_cn_c.sas7bdat") , month %in% c(5,6,7,8,9,10,11)) 
#jx_phys <- read_sas("~/Desktop/PhD project/Projects/Seatrout/Data/Raw Survey Data/Seatrout FIM Data/jxm_physical.sas7bdat") %>% select(Reference, Secchi_on_bottom, Secchi_depth)
jx_phys <- read_sas(paste(phys_dat, "jxm_physical.sas7bdat", sep="/")) %>% select(Reference, Secchi_on_bottom, Secchi_depth)
jx_phys$Reference <- as.character(jx_phys$Reference)
jx_hyd <- subset(read_sas("jx_yoy_cn_hyd.sas7bdat")) 
jx_hyd <- jx_hyd[!duplicated(jx_hyd$Reference),]
jx <- left_join(jx, jx_phys, by="Reference") %>% left_join(jx_hyd, by="Reference")
jx <- jx %>% select(noquote(order(colnames(jx))))  #reorders the columns alphabetically 
```













## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
