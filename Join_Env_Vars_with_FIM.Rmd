---
title: "Join Enviro Variables for Tampa Bay"
output: html_document
---

```{r setup, include=FALSE}
require ("knitr")
knitr::opts_chunk$set(echo = TRUE)
opts_knit$set(root.dir ="U:/PhD_projectfiles/Raw_Data/Seatrout_FIM_Data/FIMData/NEWNov7" )
```

## About

This is an R Markdown document. 
This document details how environmental data not available within the FIM dataset are appended to the FIM catch data set. 

## Set File Locations ###

Can't Use setwd for knitr so one is chosen as the root directory in the set up chunk and then if I have to reference other places then I will use other locations defined below. 
  
```{r}
personal_comp = "~/Desktop/PhD project/Projects/Seatrout/Data/Raw Survey Data/Seatrout FIM Data"
work_comp= "U:/PhD_projectfiles/Raw_Data/Seatrout_FIM_Data/FIMData/NEWNov7"
phys_dat = "U:/PhD_projectfiles/Raw_Data/Seatrout_FIM_Data/Raw Data from fimaster-data-sas-inshore"
enviro_dat = "U:/PhD_projectfiles/Raw_Data/Environmental_Data"

```

## Load Packages 
* haven-to load sas7bdat data
* dplyr- to do df manipulation
* geosphere-  closest lat/long neighbors
* cluster- to determine medoids

```{r}
library(haven) 
library(dplyr) 
library(geosphere)
library(cluster)
```

## Import Data Sets/ About Data 
The fisheries independent monitoring data (FIM) contain positive and zero catch observations of Spotted seatrout for every single haul conducted in each estuary since sampling inception.  

Load FIM Data and select the important recruitment months for each zone so that we are only selecting young-of-the-year individuals. Also, there was a typo in variable name so adjust it to be consistent with other dataframes. 
```{r Load AP}
ap = subset(read_sas("ap_yoy_cn_c.sas7bdat"), month %in% c(6,7,8,9,10,11)) %>% mutate(bUnk=bunk) %>% select(-bunk) 
```
 Load the hydro dataset that contains Depth where the observation was taken, Temperature, Conductivity, pH, Salinity, Dissolved O2
```{r Load AP 2}
ap_hyd <- subset(read_sas("ap_yoy_cn_hyd.sas7bdat")) 
```
Load the physical data set that contains secchi depth, a proxy for turbidity and turn Reference into a character. Reference will be used as a matching variable. 

```{r Load AP 3}
ap_phys <- read_sas(paste(phys_dat, "apm_physical.sas7bdat", sep="/")) %>% select(Reference, Secchi_on_bottom, Secchi_depth)
ap_phys$Reference <- as.character(ap_phys$Reference)
```

Load the hydro dataset that contains Depth where the hydro observation was taken, Temperature, Conductivity, pH, Salinity, Dissolved O2.it appears at some stations more than 1 hydro observation was recorded so there are duplicate station records. Just select the unique ones.At this point, I have no idea to know which hydro observation is more "accurat" for a certain station. 

``` {r Load AP 4}
ap_hyd <- subset(read_sas("ap_yoy_cn_hyd.sas7bdat")) 
ap_hyd <- ap_hyd[!duplicated(ap_hyd$Reference),]
```
Match merge the catch dataframe (ap) with the physical data frame (ap_phys) using the variable Reference. Then again left_join in the hydro (ap_hyd) dataset by reference. Then reorder the columns alphabetically. 

```{r Load AP 5}
ap <- left_join(ap, ap_phys, by="Reference") %>% left_join(ap_hyd, by="Reference")
ap <- ap %>% select(noquote(order(colnames(ap))))  #reorders the columns alphabetically 
```

Do this for all other estuaries.

# TB
```{r LoadTB}
tb = subset(read_sas("tb_yoy_cn_c.sas7bdat"), month %in% c(4,5,6,7,8,9,10)) 
#tb_phys <- read_sas("~/Desktop/PhD project/Projects/Seatrout/Data/Raw Survey Data/Seatrout FIM Data/tbm_physical.sas7bdat") %>% select(Reference, Secchi_on_bottom, Secchi_depth)
tb_phys <- read_sas(paste(phys_dat, "tbm_physical.sas7bdat", sep="/")) %>% select(Reference, Secchi_on_bottom, Secchi_depth)
tb_phys$Reference <- as.character(tb_phys$Reference)
tb_hyd <- subset(read_sas("tb_yoy_cn_hyd.sas7bdat")) 
tb_hyd <- tb_hyd[!duplicated(tb_hyd$Reference),]
tb <- left_join(tb, tb_phys, by="Reference") %>% left_join(tb_hyd, by="Reference")
tb <- tb %>% select(noquote(order(colnames(tb))))  #reorders the columns alphabetically 
```

Clean TB. Add in missing lat and long based on the Zone. I.e. if lat and long is missing then use lat and long for similar zone. This is necessary to be able to match any environmental data based on time and space. 

```{r clean TB}
unique(tb$Zone)
unique(subset(tb, is.na(Longitude))$Zone) #assume if its missing Long then its also missing Lat
```
Determine Zone-based medoids to apply to reference values (aka hauls) that have missing Lat Longs

```{r TB Zone specific Medoids}

tb_medA <- matrix(pam(subset(tb, Zone=="A" & !is.na(Longitude) & !is.na(Latitude), select=c("Longitude", "Latitude")),1)$medoids)
sum(is.na(tb_medA))

tb_medC <- matrix(pam(subset(tb, Zone=="C" & !is.na(Longitude) & !is.na(Latitude), select=c("Longitude", "Latitude")),1)$medoids)
sum(is.na(tb_medC))

tb_medD <- matrix(pam(subset(tb, Zone=="D" & !is.na(Longitude) & !is.na(Latitude), select=c("Longitude", "Latitude")),1)$medoids)
sum(is.na(tb_medD))

tb_medE <- matrix(pam(subset(tb, Zone=="E" & !is.na(Longitude) & !is.na(Latitude), select=c("Longitude", "Latitude")),1)$medoids)
sum(is.na(tb_medE))

tb_medM <- matrix(pam(subset(tb, Zone=="M" & !is.na(Longitude) & !is.na(Latitude), select=c("Longitude", "Latitude")),1)$medoids)
sum(is.na(tb_medM))
```
Apply zone-specific medoids to missing Long and Lat. Do this with new varaibles NewLong and NewLat 
```{r TB apply medoids to missing lat/long}
TB_main <- tb %>% mutate(NewLong = ifelse(Zone == "A" & is.na(Longitude), tb_medA[1,],  ifelse(Zone=="C" & is.na(Longitude), tb_medC[1,], ifelse(Zone == "D" & is.na(Longitude), tb_medD[1,], ifelse(Zone=="E" & is.na(Longitude), tb_medE[1,], ifelse(Zone == "M" & is.na(Longitude), tb_medM[1,], tb$Longitude))))), NewLat = ifelse(Zone == "A" & is.na(Latitude), tb_medA[2,],  ifelse(Zone=="C" & is.na(Latitude), tb_medC[2,], ifelse(Zone == "D" & is.na(Latitude), tb_medD[2,], ifelse(Zone=="E" & is.na(Latitude), tb_medE[2,], ifelse(Zone == "M" & is.na(Latitude), tb_medM[2,], tb$Latitude))))))

TB_main$year <- as.numeric(TB_main$year)
TB_main$month <- as.numeric(TB_main$month)

sum(is.na(TB_main$NewLong))                         
sum(is.na(TB_main$NewLat))   
```

Load all accessory environmental variables for Tampa Bay
* Nitrogen
* Phosphorous
* Max Air Temp-CD3
* Min Air Temp-CD3
* Palmer Z-CD3
* Rainfall
* Long-term Salinity
* Seagrass Acreage
* Streamflow
* Water Temperature 
```{r Load TB Enviro Data}
#Nitrogen#
tb_nit1 <- read.csv(paste(enviro_dat, "Nutrients/Nitrogen/Nitrogen_Hillsborough_Bay_EPC_Routine.csv", sep="/"), header=T)
tb_nit2 <- read.csv(paste(enviro_dat, "Nutrients/Nitrogen/Nitrogen_Middle_Lower_Tampa_Bay_EPC_Routine.csv", sep="/"), header=T)
tb_nit3 <- read.csv(paste(enviro_dat, "Nutrients/Nitrogen/Nitrogen_Old_Tampa_Bay_EPC_Routine.csv", sep="/"), header=T)

#Phosporous#
tb_p1 <- read.csv(paste(enviro_dat, "Nutrients/Phosphorous/Phosphorous_Hillsborough_Bay_EPC_Routine.csv", sep="/"), header=T)
tb_p2 <- read.csv(paste(enviro_dat, "Nutrients/Phosphorous/Phosphorous_Lower_Tampa_Bay_EPC_Routine.csv", sep="/"), header=T)
tb_p3 <- read.csv(paste(enviro_dat, "Nutrients/Phosphorous/Phosphorous_Middle_Tampa_Bay_EPC_Routine.csv", sep="/"), header=T)
tb_p4 <- read.csv(paste(enviro_dat, "Nutrients/Phosphorous/Phosphorous_Old_Tampa_Bay_EPC_Routine.csv", sep="/"), header=T)

tb_nit <- rbind(tb_nit1, tb_nit2, tb_nit3)
tb_ph = rbind(tb_p1, tb_p2, tb_p3, tb_p4)

#Max and Min Temp# 
tb_maxT = read.csv(paste(enviro_dat,"AirTemp/Max_Temp_CD3.csv", sep="/"), header=T, skip=5)   #skip text padding at top
tb_minT = read.csv(paste(enviro_dat,"AirTemp/Min_Temp_CD3.csv", sep="/"), header=T, skip=5)   #skip text padding at top

#Palmer Z#
tb_PalZ = read.csv(paste(enviro_dat,"PalmerZ/PalmerZ_CD3.csv", sep="/"), header=T, skip=3)    #skip text padding at top

#Rainfall#
tb_r1 = read.csv(paste(enviro_dat,"Rainfall/TB_Rainfall_89_97.csv", sep="/"))
tb_r2 = read.csv(paste(enviro_dat,"Rainfall/TB_Rainfall_98_07.csv", sep="/")) 
tb_r3 = read.csv(paste(enviro_dat,"Rainfall/TB_Rainfall_08_17.csv", sep="/")) 
tb_rain = rbind(tb_r1, tb_r2, tb_r3)

# Salinity #
tb_Sal = rbind(read.csv(paste(enviro_dat,"Salinity/TB/Salinity_HillsboroughBay_EPCRoutine.csv", sep="/")),                   read.csv(paste(enviro_dat,"Salinity/TB/Salinity_LowerTampaBay_EPCRoutine.csv", sep="/")),
             read.csv(paste(enviro_dat,"Salinity/TB/Salinity_MiddleTampaBay_EPCRoutine.csv", sep="/")),
             read.csv(paste(enviro_dat,"Salinity/TB/Salinity_OldTampaBay_EPCRoutine.csv", sep="/")))

# Seagrass #
tb_SeaG = read.csv(paste(enviro_dat,"Seagrass Cover/SWFWMD_Seagrass_TB.csv", sep="/"))

# Stream Flow #
SF = read.csv(paste(enviro_dat,"Streamflow/TB/Alafia_River.csv", sep="/"), header=T, skip=28) %>% rename(Val=X25177_00060_00003, Cd = X25177_00060_00003_cd)
SF1 = read.csv(paste(enviro_dat,"Streamflow/TB/Hillsborough_river.csv", sep="/"), header=T, skip=28) %>% rename(Val= X25432_00060_00003, Cd= X25432_00060_00003_cd)
SF2 = read.csv(paste(enviro_dat,"Streamflow/TB/Little.Manatee_River.csv", sep="/"), header=T, skip=28) %>% rename(Val=X25075_00060_00003, Cd=X25075_00060_00003_cd)

tb_StrF = rbind(SF, SF1, SF2)

#WaterTemp #

wt = read.csv(paste(enviro_dat,"WaterTemp/TB/Water_temperature_Hillsborough_Bay.csv",  sep="/"), header=T)
wt1 = read.csv(paste(enviro_dat,"WaterTemp/TB/Water_temperature_Lower_Tampa_Bay.csv",  sep="/"), header=T)
wt2 = read.csv(paste(enviro_dat,"WaterTemp/TB/Water_temperature_Middle_Tampa_Bay.csv",  sep="/"), header=T)

tb_wtrT = rbind(wt, wt1, wt2)

rm(wt, wt1, wt2, SF, SF1, SF2, tb_r1, tb_r2, tb_r3, tb_p1, tb_p2, tb_p3, tb_p4, tb_nit1, tb_nit2, tb_nit3) 

```

Now that all data are loaded I need to join them spatially and temporally. Temporal matching will have two set-ups (depending on the data type). 

 * spatially- by closest lat and long
 * temporally (set up 1)- by month of FIM haul 
 * temporally (set up 2) - lagged 

Temporal Set up 1 - At month/time  of sampling
* Max Temp- max temp that month if sampling happened at end of month, if sampling happened             in beginning of month then do last month max: average max temp of closest                 month)
* Min Temp- min temp of closest month
* Nutrients - nitrogen and phosphorous load of closest month 
* Drought - drought index of closest month
* Rain fall - total rainfall of closest month
* Salinity (from FIM)
* Streamflow - total streamflow of closest month
* Water Temp (from FIM)

Temporal Set up 2 - Lagged 
* Max Temp - average maximum air temperature prior 
* Min Temp - average minimum air temperature prior
* Nutrients - total nitrogen load 2 months prior
* Drought - average drought index prior 
* Rainfall - total year-specific rainfall to-date starting at time of spawning
* Streamflow - total year-specific streamflow to-date starting at time of spawning
* Salinity - average salinity prior
* WaterTemp - average water temp prior 


Need to format the environmental data to achieve the above described matching. 

```{r Format Enviro Data}
tb_nit$SampleDate <- as.factor(tb_nit$SampleDate)
tb_nit <- tb_nit %>% mutate(Date = as.Date(SampleDate, format = " %m/%d/%Y"))
tb_nit$Date <- as.character(tb_nit$Date)

tb_nit <- tb_nit %>% mutate(Year = substr(Date, 1,4), Month = substr(Date, 6,7)) %>% subset(Characteristic %in% c("Nitrogen") & (Year >1988 & Year<2016)) %>% select(Actual_Latitude, Actual_Longitude, Characteristic,Parameter,Result_Unit, Result_Value, Year, Month, StationID)
tb_nit$Year <- as.numeric(tb_nit$Year)
tb_nit$Month <- as.numeric(tb_nit$Month)
```

First define the spatial scale of matching.
Starting with lat and long fuzzy matching. 

```{r}
range(unique(tb_nit$Actual_Latitude)) #determine the total range of latitudes in the TB_nit
#27.5737 - 27.9904
range(unique(TB_main$NewLat)) #determine the total range of lat in the TB_main
# 27.466 -  28.03467

range(unique(tb_nit$Actual_Longitude)) #determine the total range of longs in the TB_nit
# -82.7441 - -82.4093
range(unique(TB_main$NewLong))
# -82.831 - -82.333
```
Determine difference between minimum lats of tb_nit and TB_main and difference between maximum lats of tb_nit and TB_main to determine how far or fuzzy things could be.
Do this same thing for longitude. 
```{r}
min(unique(tb_nit$Actual_Latitude)) - min(unique(TB_main$NewLat)) #0.1068669
max(unique(tb_nit$Actual_Latitude)) - max(unique(TB_main$NewLat)) #0.0442667

min(unique(tb_nit$Actual_Longitude)) - min(unique(TB_main$NewLong)) #0.0868976
max(unique(tb_nit$Actual_Longitude)) - max(unique(TB_main$NewLong)) #0.07563469
```
Fuzzy lat distance must be at least 0.1068669 or else the minimum lat observations from the TB_main will not be able to find a fuzzy match. In other words, a fuzzy match of less than that, say for the distance between maximum (0.044), will mean that the minimum lats will not find a match because they are separated by 0.1068669

Fuzzy long distance must be at least 0.0868976 per above logic. 

Run the loop using the defined fuzzy match.

```{r}
#fuzzy_lat = max(min(unique(tb_nit$Actual_Latitude)) - min(unique(TB_main$NewLat)), max(unique(tb_nit$Actual_Latitude)) - max(unique(TB_main$NewLat)))

#fuzzy_long = max(min(unique(tb_nit$Actual_Longitude)) - min(unique(TB_main$NewLong)),max(unique(tb_nit$Actual_Longitude)) - max(unique(TB_main$NewLong)))

fuzzy_lat = 0.1
fuzzy_long = 0.1 

# Build function for spatial and temporal matching



TB_main =TB_main[1:5,]

selected <- NULL

match = function(main, EnviroDS, fuzzy_lat, fuzzy_long){
  selected <- NULL
for(i in 1:nrow(main))
{
  # re-initialize these data structs for new pass
  match_matrix <- NULL
  #names(match_matrix) <- c("catch month", "catch year", "refID", "nit_val", "nit_lat","nit_long","dist")
  Comb <- data.frame(Month=numeric(),Year=numeric(),RefID=numeric(),Value=numeric(),Latitude=numeric(),Longitude=numeric())
  
  #define some variables
  catch_year=main[i,61]
  catch_month= main[i,30]
  catch_lat= main[i,65]
  catch_long= main[i, 64]
  catch_ref =  main[i,41]
  coordinates = as.numeric(c(main[i,64], main[i,65]))
  
  for(j in 1:nrow(EnviroDS))
  {
    #define some variables
    env_year=EnviroDS[j,7]
    env_month=EnviroDS[j,8]
    env_lat =EnviroDS[j,1]
    env_long = EnviroDS[j,2]
    env_val = EnviroDS[j,6]
    
    if (is.na(catch_year) | is.na(catch_month) | is.na(catch_lat) | is.na(catch_long))
    {
      print("NA Found")
    }
    else if((catch_year==env_year)&(catch_month==env_month))
    {
      #defining box to place around each coordinate pair assocaited with catch
      # this reduces the amount of coordinate points that are selected from within tb_nit that are then used in a pairwise distance comparison
      
      fuzzymax_lat = catch_lat +fuzzy_lat #main$NewLat
      fuzzymin_lat = catch_lat -fuzzy_lat
      fuzzymax_long = catch_long + fuzzy_long #main$NewLong
      fuzzymin_long = catch_long - fuzzy_long
      
      if((env_lat > fuzzymin_lat) & (env_lat < fuzzymax_lat) & (env_long > fuzzymin_long) & (env_long < fuzzymax_long)) 
        #if the lat long of enviro data set falls within the fuzzy lat long boundaries of the catch lat long found above then it will add into the dataframe below 
      {
        
        m=NULL
        m[1] = catch_month
        m[2]=catch_year
        m[3]= catch_ref     
        m[4] = env_val
        m[5] = env_long
        m[6] = env_lat
        m[7]= as.numeric(NA) # placeholder for distance 
        
        match_matrix <- rbind(match_matrix,m) #builds on to mmatch matrix as it cycles through j rows
        mm_mat <- matrix(unlist(match_matrix),nrow=nrow(match_matrix)) #gets the coordinates in the right form 
        mm_mat[,7] = distm(mm_mat[,5:6], coordinates)
        mm_df <- data.frame(mm_mat)
        colnames(mm_df) <- c("a", "b", "c", "d", "e", "f", "g")
        mm_df$g <- as.numeric(as.character(mm_df$g))
        
        env_station_match = NULL
        env_station_match <- as.matrix(mm_df[mm_df$g == min(mm_df$g),])
        #selected <- rbind(selected, nit_station)
        
      }
    }
  }
  selected <- rbind(selected, env_station_match)
}

  
  }


match(TB_main, tb_nit, 0.1, 0.1) 



fuzzy_lat=0.1
fuzzy_long=0.1


selected <- NULL

for(i in 1:nrow(TB_main)){
  # re-initialize these data structs for new pass
  match_matrix <- NULL
  #names(match_matrix) <- c("catch month", "catch year", "refID", "nit_val", "nit_lat","nit_long","dist")
  TBcomb <- data.frame(Month=numeric(),Year=numeric(),RefID=numeric(),Nitrogen=numeric(),Latitude=numeric(),Longitude=numeric())
  hit_counter = 1
  
  #define some variables
  catch_year=TB_main[1,61]
  catch_month=TB_main[1,30]
  catch_lat=TB_main[1,65]
  catch_long=TB_main[1, 64]
  catch_ref = TB_main[1,41]
  TB_cor = as.numeric(c(TB_main[1,64], TB_main[1,65]))
  

  for(j in 1:nrow(tb_nit))
  {
    #define some variables
    nit_year=tb_nit[j,7]
    nit_month=tb_nit[j,8]
    nit_lat =tb_nit[j,1]
    nit_long = tb_nit[j,2]
    nit_val = tb_nit[j,6]
    
    if (is.na(catch_year) | is.na(catch_month) | is.na(catch_lat) | is.na(catch_long))
    {
      print("NA Found")
    }
    else if((catch_year==nit_year)&(catch_month==nit_month))
    {
      #defining box to place around each coordinate pair assocaited with catch
      # this reduces the amount of coordinate points that are selected from within tb_nit that are then used in a pairwise distance comparison
      
      fuzzymax_lat = catch_lat +fuzzy_lat #TB_main_sub$NewLat
      fuzzymin_lat = catch_lat -fuzzy_lat
      fuzzymax_long = catch_long + fuzzy_long #TBmain$NewLong
      fuzzymin_long = catch_long - fuzzy_long
      
      if((nit_lat > fuzzymin_lat) & (nit_lat < fuzzymax_lat) & (nit_long > fuzzymin_long) & (nit_long < fuzzymax_long)) 
        #if the lat long of nitrogen falls within the fuzzy lat long boundaries of the catch lat long found above then it will add into the dataframe below 
      {
        
        # TBcomb[hit_counter,1] = catch_month
        # TBcomb[hit_counter,2] = catch_year
        # TBcomb[hit_counter,3] = catch_ref
        # TBcomb[hit_counter,4] = nit_val #result value
        # TBcomb[hit_counter, 5] = nit_lat
        # TBcomb[hit_counter, 6] = nit_long
        # hit_counter = hit_counter + 1
        
        m=NULL
        m[1] = catch_month
        m[2]=catch_year
        m[3]= catch_ref     
        m[4] = nit_val
        m[5] = nit_long
        m[6] = nit_lat
        m[7]= as.numeric(NA) # placeholder for distance 
        
        match_matrix <- rbind(match_matrix,m)
        mm_mat <- matrix(unlist(match_matrix),nrow=nrow(match_matrix))
        mm_mat[,7] = distm(mm_mat[,5:6], TB_cor)
        mm_df <- data.frame(mm_mat)
        colnames(mm_df) <- c("a", "b", "c", "d", "e", "f", "g")
        mm_df$g <- as.numeric(as.character(mm_df$g))
        
        nit_station_match = NULL
        nit_station_match <- as.matrix(mm_df[mm_df$g == min(mm_df$g),])
        #selected <- rbind(selected, nit_station)
        
      }
    }
  }
  selected <- rbind(selected, nit_station_match)
  
  
  
  
}































```



      

#CK
```{r Load CK, include =FALSE}
ck = subset(read_sas("ck_yoy_cn_c.sas7bdat"),  month %in% c(5,6,7,8,9,10,11))
#ck_phys <- read_sas("~/Desktop/PhD project/Projects/Seatrout/Data/Raw Survey Data/Seatrout FIM Data/ckm_physical.sas7bdat") %>% select(Reference, Secchi_on_bottom, Secchi_depth)
ck_phys <- read_sas(paste(phys_dat, "ckm_physical.sas7bdat", sep="/")) %>% select(Reference, Secchi_on_bottom, Secchi_depth)
ck_phys$Reference <- as.character(ck_phys$Reference)
ck_hyd <- subset(read_sas("ck_yoy_cn_hyd.sas7bdat")) 
ck_hyd <- ck_hyd[!duplicated(ck_hyd$Reference),]
ck <- left_join(ck, ck_phys, by="Reference") %>% left_join(ck_hyd, by="Reference")
ck <- ck %>% select(noquote(order(colnames(ck))))  #reorders the columns alphabetically 
```
             
                         
#CH
``` {r Load CH, include=FALSE}
ch = subset(read_sas("ch_yoy_cn_c.sas7bdat"), month %in% c(4,5,6,7,8,9,10)) %>% mutate(bUnk=bunk) %>% select(-bunk) 
#ch_phys <- read_sas("~/Desktop/PhD project/Projects/Seatrout/Data/Raw Survey Data/Seatrout FIM Data/chm_physical.sas7bdat") %>% select(Reference, Secchi_on_bottom, Secchi_depth)
ch_phys <- read_sas(paste(phys_dat, "chm_physical.sas7bdat", sep="/")) %>% select(Reference, Secchi_on_bottom, Secchi_depth)
ch_phys$Reference <- as.character(ch_phys$Reference)
ch_hyd <- subset(read_sas("ch_yoy_cn_hyd.sas7bdat")) 
#Also duplicated References in ch_hyd
ch_hyd <- ch_hyd[!duplicated(ch_hyd$Reference),]
ch <- left_join(ch, ch_phys, by="Reference") %>% left_join(ch_hyd, by="Reference")
ch <- ch %>% select(noquote(order(colnames(ch))))  #reorders the columns alphabetically 
```

#IR
```{r Load IR, include=FALSE}
ir = subset(read_sas("ir_yoy_cn_c.sas7bdat"), month %in% c(5,6,7,8,9,10,11)) 
#ir_phys <- read_sas("~/Desktop/PhD project/Projects/Seatrout/Data/Raw Survey Data/Seatrout FIM Data/irm_physical.sas7bdat") %>% select(Reference, Secchi_on_bottom, Secchi_depth)
ir_phys <- read_sas(paste(phys_dat, "irm_physical.sas7bdat", sep="/")) %>% select(Reference, Secchi_on_bottom, Secchi_depth)
ir_phys$Reference <- as.character(ir_phys$Reference)
ir_hyd <- subset(read_sas("ir_yoy_cn_hyd.sas7bdat")) 
#Also duplicated References in ir_hyd
ir_hyd <- ir_hyd[!duplicated(ir_hyd$Reference),]
ir <- left_join(ir, ir_phys, by="Reference") %>% left_join(ir_hyd, by="Reference")
ir <- ir %>% select(noquote(order(colnames(ir))))  #reorders the columns alphabetically 
```

#JX
```{r Load JX, include=FALSE}
jx = subset(read_sas("jx_yoy_cn_c.sas7bdat") , month %in% c(5,6,7,8,9,10,11)) 
#jx_phys <- read_sas("~/Desktop/PhD project/Projects/Seatrout/Data/Raw Survey Data/Seatrout FIM Data/jxm_physical.sas7bdat") %>% select(Reference, Secchi_on_bottom, Secchi_depth)
jx_phys <- read_sas(paste(phys_dat, "jxm_physical.sas7bdat", sep="/")) %>% select(Reference, Secchi_on_bottom, Secchi_depth)
jx_phys$Reference <- as.character(jx_phys$Reference)
jx_hyd <- subset(read_sas("jx_yoy_cn_hyd.sas7bdat")) 
jx_hyd <- jx_hyd[!duplicated(jx_hyd$Reference),]
jx <- left_join(jx, jx_phys, by="Reference") %>% left_join(jx_hyd, by="Reference")
jx <- jx %>% select(noquote(order(colnames(jx))))  #reorders the columns alphabetically 
```













## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
